{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import fasttext\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize text\n",
    "def normalize_text(texts, stops=None):\n",
    "    # Lower case\n",
    "    texts = [x.lower() for x in texts]\n",
    "\n",
    "    # EOL\n",
    "    texts = [re.compile(r\"\\\\n\").sub(' ',x) for x in texts]\n",
    "    \n",
    "    # Replace punctuation with space\n",
    "    texts = [x.translate(x.maketrans(string.punctuation, ' '*len(string.punctuation))) for x in texts]\n",
    "    \n",
    "    # Remove numbers\n",
    "    texts = [''.join(c for c in x if c not in '0123456789') for x in texts]\n",
    "    \n",
    "    if stops:\n",
    "        # Remove stopwords\n",
    "        texts = [' '.join([word for word in x.split() if word not in (stops)]) for x in texts]\n",
    "\n",
    "#     # split into list\n",
    "#     texts = [x.split() for x in texts]\n",
    "    \n",
    "    return(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_Imdb_data():\n",
    "    train = pd.read_csv('data/Large Movie Review Dataset/train.csv')\n",
    "    test = pd.read_csv('data/Large Movie Review Dataset/test.csv')\n",
    "    train_X = train['text'].values.tolist()\n",
    "    train_y = train['label'].values.tolist()\n",
    "    test_X = test['text'].values.tolist()\n",
    "    test_y = test['label'].values.tolist()\n",
    "    return train,test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMDB train data size: 25000\n",
      "label\n",
      "0    12500\n",
      "1    12500\n",
      "dtype: int64\n",
      "IMDB test data size: 25000\n",
      "label\n",
      "0    12500\n",
      "1    12500\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "train_data, test_data = load_Imdb_data()\n",
    "print('IMDB train data size: %d' % len(train_data))\n",
    "print(train_data.groupby('label').size())\n",
    "print('IMDB test data size: %d' % len(test_data))\n",
    "print(test_data.groupby('label').size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_data['text'].values.tolist()\n",
    "train_y = train_data['label'].values.tolist()\n",
    "test_X = test_data['text'].values.tolist()\n",
    "test_y = test_data['label'].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stops = stopwords.words('english')\n",
    "normalized_train_X = normalize_text(train_X, stops)\n",
    "normalized_test_X = normalize_text(test_X, stops)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix_y = ['__label__'+ str(y) for y in train_y]\n",
    "test_prefix_y = ['__label__'+ str(y) for y in test_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix_data=pd.DataFrame({'train_y': train_prefix_y,'text': normalized_train_X})\n",
    "test_prefix_data=pd.DataFrame({'train_y': test_prefix_y,'text': normalized_test_X})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_prefix_data.to_csv('train_prefix.txt', sep='\\t', index = False, header = False)\n",
    "test_prefix_data.to_csv('test_prefix.txt', sep='\\t', index = False, header = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fasttext.train_supervised('train_prefix.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "went saw movie last night coaxed friends mine admit reluctant see knew ashton kutcher able comedy wrong kutcher played character jake fischer well kevin costner played ben randall professionalism sign good movie toy emotions one exactly entire theater sold overcome laughter first half movie moved tears second half exiting theater saw many women tears many full grown men well trying desperately let anyone see crying movie great suggest go see judge __label__1\n",
      "(('__label__1',), array([0.81123638]))\n"
     ]
    }
   ],
   "source": [
    "print(normalized_test_X[0],test_prefix_y[0])\n",
    "print(model.predict(test_X[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = model.test('test_prefix.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t\t25000\n",
      "precision\t0.877\n",
      "recall\t\t0.877\n"
     ]
    }
   ],
   "source": [
    "def print_results(N, p, r):\n",
    "    print(\"N\\t\\t\" + str(N))\n",
    "    print(\"precision\\t{:.3f}\".format(p))\n",
    "    print(\"recall\\t\\t{:.3f}\".format(r))\n",
    "print_results(*validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = [model.predict(text)[0][0] for text in normalized_test_X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.87744"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(test_prefix_y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[11211,  1289],\n",
       "       [ 1775, 10725]], dtype=int64)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(test_prefix_y, y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "  __label__0       0.86      0.90      0.88     12500\n",
      "  __label__1       0.89      0.86      0.88     12500\n",
      "\n",
      "    accuracy                           0.88     25000\n",
      "   macro avg       0.88      0.88      0.88     25000\n",
      "weighted avg       0.88      0.88      0.88     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(test_prefix_y, y_predict, target_names=['__label__0','__label__1']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
